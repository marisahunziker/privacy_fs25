{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9ea491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b223b995",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 6.5  # in inches\n",
    "height = width * 0.75  # 4:3 aspect ratio\n",
    "fig_size = (width, height)\n",
    "\n",
    "reds = sns.color_palette(\"Reds\", 6)\n",
    "blues = sns.color_palette(\"Blues\", 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf3121e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_multipliers = [0.5, 0.75, 1.0, 1.25, 1.5, 2.0]\n",
    "experiments = list(noise_multipliers)\n",
    "\n",
    "len(experiments)\n",
    "\n",
    "figure_base_path = \"figures/dp/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0213cc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss for noise multiplier 0.5: 1.2524595657238662\n",
      "Last loss for noise multiplier 0.75: 1.0897101980846169\n",
      "Last loss for noise multiplier 1.25: 1.2661134333122226\n",
      "Last loss for noise multiplier 1.5: 1.4236726948378826\n"
     ]
    }
   ],
   "source": [
    "losses = {}\n",
    "losses[0.5] = torch.load('../losses/dp/17-07/losses_dp_1_epoch301.pt')\n",
    "\n",
    "losses[0.75] = torch.load('../losses/dp/17-07/losses_dp_2_epoch600.pt')\n",
    "# losses[1.0] = torch.load('../losses/dp/17-07/losses_dp_1.0_epoch??.pt')\n",
    "losses[1.25] = torch.load('../losses/dp/17-07/losses_dp_1_epoch600.pt')\n",
    "losses[1.5] = torch.load('../losses/dp/17-07/losses_dp_2_epoch420.pt')\n",
    "\n",
    "for key in losses:\n",
    "    print(f\"Last loss for noise multiplier {key}: {losses[key]['train_loss'][-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82b7aef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last metric for noise multiplier 0.5: [{'epsilon': 0.5, 'delta': 1e-05, 'iterations': 5470, 'mse': 17.156686782836914, 'mae': 3.607133388519287, 'rmse': 4.142063107056303}, {'epsilon': 1.0, 'delta': 1e-05, 'iterations': 5470, 'mse': 17.156686782836914, 'mae': 3.607133388519287, 'rmse': 4.142063107056303}, {'epsilon': 1.5, 'delta': 1e-05, 'iterations': 5470, 'mse': 17.156686782836914, 'mae': 3.607133388519287, 'rmse': 4.142063107056303}, {'epsilon': 2.0, 'delta': 1e-05, 'iterations': 5470, 'mse': 17.156686782836914, 'mae': 3.607133388519287, 'rmse': 4.142063107056303}, {'epsilon': 2.5, 'delta': 1e-05, 'iterations': 5470, 'mse': 17.156686782836914, 'mae': 3.607133388519287, 'rmse': 4.142063107056303}, {'epsilon': 3.0, 'delta': 1e-05, 'iterations': 5470, 'mse': 17.156686782836914, 'mae': 3.607133388519287, 'rmse': 4.142063107056303}, {'epsilon': 3.5, 'delta': 1e-05, 'iterations': 32820, 'mse': 15.032976150512695, 'mae': 3.4394876956939697, 'rmse': 3.877238211731734}, {'epsilon': 4.0, 'delta': 1e-05, 'iterations': 87520, 'mse': 14.692313194274902, 'mae': 3.3464903831481934, 'rmse': 3.8330553341003184}, {'epsilon': 4.5, 'delta': 1e-05, 'iterations': 164100, 'mse': 13.809796333312988, 'mae': 3.156419277191162, 'rmse': 3.716153432423504}, {'epsilon': 5.0, 'delta': 1e-05, 'iterations': 257090, 'mse': 11.722628593444824, 'mae': 2.778367280960083, 'rmse': 3.4238324423728486}, {'epsilon': 5.5, 'delta': 1e-05, 'iterations': 361020, 'mse': 8.726775169372559, 'mae': 2.246047258377075, 'rmse': 2.954111570230982}, {'epsilon': 6.0, 'delta': 1e-05, 'iterations': 475890, 'mse': 5.8036909103393555, 'mae': 1.7299991846084595, 'rmse': 2.409085077439017}, {'epsilon': 6.5, 'delta': 1e-05, 'iterations': 601700, 'mse': 3.6688458919525146, 'mae': 1.3327155113220215, 'rmse': 1.9154231626333944}, {'epsilon': 7.0, 'delta': 1e-05, 'iterations': 732980, 'mse': 2.414874315261841, 'mae': 1.0927811861038208, 'rmse': 1.553986587864207}, {'epsilon': 7.5, 'delta': 1e-05, 'iterations': 869730, 'mse': 1.7609113454818726, 'mae': 0.9608766436576843, 'rmse': 1.326993347941832}, {'epsilon': 8.0, 'delta': 1e-05, 'iterations': 1017420, 'mse': 1.4133341312408447, 'mae': 0.8893077969551086, 'rmse': 1.1888373022583218}, {'epsilon': 8.5, 'delta': 1e-05, 'iterations': 1165110, 'mse': 1.2314320802688599, 'mae': 0.8477103114128113, 'rmse': 1.1096990944705956}, {'epsilon': 9.0, 'delta': 1e-05, 'iterations': 1323740, 'mse': 1.1239433288574219, 'mae': 0.8236398100852966, 'rmse': 1.060161935204911}, {'epsilon': 9.5, 'delta': 1e-05, 'iterations': 1482370, 'mse': 1.0664786100387573, 'mae': 0.8095003962516785, 'rmse': 1.0327045124520167}, {'epsilon': 10.0, 'delta': 1e-05, 'iterations': 1646470, 'mse': 1.0303457975387573, 'mae': 0.7988182902336121, 'rmse': 1.0150595044325024}]\n",
      "Last metric for noise multiplier 0.75: [{'epsilon': 0.5, 'delta': 1e-05, 'iterations': 5470, 'mse': 16.928577423095703, 'mae': 3.542790412902832, 'rmse': 4.114435249593279}, {'epsilon': 1.0, 'delta': 1e-05, 'iterations': 5470, 'mse': 16.928577423095703, 'mae': 3.542790412902832, 'rmse': 4.114435249593279}, {'epsilon': 1.5, 'delta': 1e-05, 'iterations': 541530, 'mse': 4.485195159912109, 'mae': 1.5043965578079224, 'rmse': 2.1178279344441817}, {'epsilon': 2.0, 'delta': 1e-05, 'iterations': 1219810, 'mse': 1.207565426826477, 'mae': 0.8455208539962769, 'rmse': 1.0988928186254003}, {'epsilon': 2.5, 'delta': 1e-05, 'iterations': 1930910, 'mse': 1.0139175653457642, 'mae': 0.7909095883369446, 'rmse': 1.0069347373816062}, {'epsilon': 3.0, 'delta': 1e-05, 'iterations': 2696710, 'mse': 0.9459819793701172, 'mae': 0.7639582753181458, 'rmse': 0.9726160493072882}]\n",
      "Last metric for noise multiplier 1.25: [{'epsilon': 0.5, 'delta': 1e-05, 'iterations': 530590, 'mse': 5.191648960113525, 'mae': 1.6274712085723877, 'rmse': 2.2785190278146734}, {'epsilon': 1.0, 'delta': 1e-05, 'iterations': 2034840, 'mse': 1.0921850204467773, 'mae': 0.8202128410339355, 'rmse': 1.04507656200241}]\n",
      "Last metric for noise multiplier 1.5: [{'epsilon': 0.5, 'delta': 1e-05, 'iterations': 908020, 'mse': 2.03509259223938, 'mae': 1.0276844501495361, 'rmse': 1.4265667149626686}]\n"
     ]
    }
   ],
   "source": [
    "metrics = {}\n",
    "\n",
    "metrics[0.5] = torch.load('../metrics/dp/17-07/metrics_dp_1_epoch301.pt', weights_only=False)\n",
    "metrics[0.75] = torch.load('../metrics/dp/17-07/metrics_dp_2_epoch600.pt', weights_only=False)\n",
    "# metrics[1.0] = torch.load('../metrics/dp/17-07/metrics_dp_1.0_epoch??.pt', weights_only=False)\n",
    "metrics[1.25] = torch.load('../metrics/dp/17-07/metrics_dp_1_epoch600.pt', weights_only=False)\n",
    "metrics[1.5] = torch.load('../metrics/dp/17-07/metrics_dp_2_epoch420.pt', weights_only=False)\n",
    "\n",
    "for key in metrics:\n",
    "    print(f\"Last metric for noise multiplier {key}: {metrics[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb432c71",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m loss_files = []\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(experiments) + \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     file_pattern = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m../losses/np/14-07/losses_dp_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_epoch\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mlatest_epochs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pt\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     18\u001b[39m     loss_files.extend(glob.glob(file_pattern))\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Load the losses from each file and store them in a dictionary, with the experiment number as key\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: 1"
     ]
    }
   ],
   "source": [
    "# Find the latest epoch number in the filenames, this can depend on the experiment\n",
    "latest_epochs = {}\n",
    "for i in range(1, len(experiments) + 1):\n",
    "    files = glob.glob(f'../losses/np/14-07/losses_dp_{i}_epoch*.pt')\n",
    "    if files:\n",
    "        latest_epoch = max(int(os.path.basename(f).split('_')[-1].replace('epoch', '').replace('.pt', '')) for f in files)\n",
    "        latest_epochs[i] = latest_epoch\n",
    "\n",
    "# Now we will load the losses for each experiment at the latest epoch\n",
    "loss_files = []\n",
    "for i in range(1, len(experiments) + 1):\n",
    "    file_pattern = f'../losses/np/14-07/losses_dp_{i}_epoch{latest_epochs[i]}.pt'\n",
    "    loss_files.extend(glob.glob(file_pattern))\n",
    "\n",
    "\n",
    "# Load the losses from each file and store them in a dictionary, with the experiment number as key\n",
    "losses = {}\n",
    "for file in loss_files:\n",
    "    experiment_nr = int(file.split('_')[2])  # Extract the experiment number from the filename\n",
    "    losses[experiment_nr] = torch.load(file)\n",
    "\n",
    "losses[1]['train_loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacc56e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train_loss, validation_loss, experiment_nr):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    plt.plot(train_loss, label='Train Loss', color='blue')\n",
    "    plt.plot(validation_loss, label='Validation Loss', color='orange')\n",
    "    plt.title(f'Losses for Experiment {experiment_nr}: noise multiplier={experiments[experiment_nr-1]}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{figure_base_path}losses_experiment_{experiment_nr}.pdf')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "for i in range(1, 10):\n",
    "    plot_loss(losses[i]['train_loss'], losses[i]['val_loss'], i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3322736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiment': 1,\n",
       " 'epoch': 100,\n",
       " 'mse': 0.9895796775817871,\n",
       " 'mae': 0.7962299585342407,\n",
       " 'rmse': 0.9947761947200924}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_files = glob.glob('../metrics/np/14-07/metrics_dp_*_epoch*.pt')\n",
    "\n",
    "# Load the metrics from each file and store them in a dictionary, with the experiment number as key \n",
    "metrics = {}\n",
    "for file in metric_files:\n",
    "    experiment_nr = int(file.split('_')[2])  # Extract the experiment number from the filename\n",
    "    epoch = int(file.split('_')[-1].replace('epoch', '').replace('.pt', ''))  # Extract the epoch number\n",
    "    if experiment_nr not in metrics:\n",
    "        metrics[experiment_nr] = {}\n",
    "    metrics[experiment_nr][epoch] = torch.load(file, weights_only=False)\n",
    "\n",
    "metrics[1][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfd5211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics, experiment_nr):\n",
    "    # Plot the metrics for a specific experiment\n",
    "    # on the x-axis we have the epochs, on the y-axis we have the metric value\n",
    "    # The metric values are mse, mae, and rmse\n",
    "    for experiment_nr in metrics.keys():\n",
    "        epochs = sorted(metrics[experiment_nr].keys())\n",
    "        mse = [metrics[experiment_nr][epoch]['mse'] for epoch in epochs]\n",
    "        mae = [metrics[experiment_nr][epoch]['mae'] for epoch in epochs]\n",
    "        plt.figure(figsize=fig_size)\n",
    "        plt.plot(epochs, mse, label='MSE', color='blue')\n",
    "        plt.plot(epochs, mae, label='MAE', color='orange')\n",
    "        plt.title(f'Metrics for Experiment {experiment_nr}: noise multiplier={experiments[experiment_nr-1]}')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Metric Value')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'{figure_base_path}metrics_experiment_{experiment_nr}.pdf')\n",
    "        plt.close()\n",
    "\n",
    "    \n",
    "for i in range(1, len(experiments) + 1):\n",
    "    if i in metrics:\n",
    "        plot_metrics(metrics, i)\n",
    "    else:\n",
    "        print(f\"No metrics found for experiment {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89600a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([3, 1, 9, 4, 2, 7, 8, 6, 5])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_mse(metrics):\n",
    "    # Plot the MSE for all experiments\n",
    "    plt.figure(figsize=fig_size)\n",
    "    for experiment_nr in metrics.keys():\n",
    "        epochs = sorted(metrics[experiment_nr].keys())\n",
    "        mse = [metrics[experiment_nr][epoch]['mse'] for epoch in epochs]\n",
    "        plt.plot(epochs, mse, label=f'Experiment {experiment_nr}')\n",
    "    plt.title('MSE for All Experiments')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{figure_base_path}mse_all_experiments.pdf')\n",
    "    plt.close()\n",
    "\n",
    "plot_mse(metrics)\n",
    "\n",
    "metrics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b8efe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal MSE: 0.9895796775817871 in Experiment 1\n",
      "Minimal MAE: 0.7962299585342407 in Experiment 1\n",
      "Minimal RMSE: 0.9947761947200924 in Experiment 1\n"
     ]
    }
   ],
   "source": [
    "# Experiment with the minimal metric values \n",
    "def minimal_metrics(metrics):\n",
    "    # Find the experiment number with the minimal MSE, MAE, and RMSE at epoch 100\n",
    "    min_mse = float('inf')\n",
    "    min_mae = float('inf')\n",
    "    min_rmse = float('inf')\n",
    "    min_mse_experiment = None\n",
    "    min_mae_experiment = None\n",
    "    min_rmse_experiment = None\n",
    "    for experiment_nr in metrics.keys():\n",
    "        mse = metrics[experiment_nr][100]['mse']\n",
    "        mae = metrics[experiment_nr][100]['mae']\n",
    "        rmse = metrics[experiment_nr][100]['rmse']\n",
    "        if mse < min_mse:\n",
    "            min_mse = mse\n",
    "            min_mse_experiment = experiment_nr\n",
    "        if mae < min_mae:\n",
    "            min_mae = mae\n",
    "            min_mae_experiment = experiment_nr\n",
    "        if rmse < min_rmse:\n",
    "            min_rmse = rmse\n",
    "            min_rmse_experiment = experiment_nr\n",
    "    print(f'Minimal MSE: {min_mse} in Experiment {min_mse_experiment}')\n",
    "    print(f'Minimal MAE: {min_mae} in Experiment {min_mae_experiment}')\n",
    "    print(f'Minimal RMSE: {min_rmse} in Experiment {min_rmse_experiment}')\n",
    "\n",
    "minimal_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cd494a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal Train Loss: 0.8843784033541316 in Experiment 1\n",
      "Minimal Validation Loss: 0.8281576169557989 in Experiment 1\n"
     ]
    }
   ],
   "source": [
    "def minimal_loss(losses):\n",
    "    # Find the experiment number with the minimal train and validation loss at epoch 100\n",
    "    min_train_loss = float('inf')\n",
    "    min_val_loss = float('inf')\n",
    "    min_train_loss_experiment = None\n",
    "    min_val_loss_experiment = None\n",
    "    for experiment_nr in losses.keys():\n",
    "        train_loss = losses[experiment_nr]['train_loss'][-1]  # Last value is at epoch 100\n",
    "        val_loss = losses[experiment_nr]['val_loss'][-1]  # Last value is at epoch 100\n",
    "        if train_loss < min_train_loss:\n",
    "            min_train_loss = train_loss\n",
    "            min_train_loss_experiment = experiment_nr\n",
    "        if val_loss < min_val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            min_val_loss_experiment = experiment_nr\n",
    "    print(f'Minimal Train Loss: {min_train_loss} in Experiment {min_train_loss_experiment}')\n",
    "    print(f'Minimal Validation Loss: {min_val_loss} in Experiment {min_val_loss_experiment}')\n",
    "\n",
    "minimal_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0964269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1 - MSE: 0.8298844695091248, MAE: 0.7222684621810913, RMSE: 0.910979950113681\n",
      "Experiment 1 - Train Loss: 0.8843784033541316, Validation Loss: 0.8281576169557989\n",
      "Experiment 2 - MSE: 0.974905788898468, MAE: 0.7888841032981873, RMSE: 0.9873731761084398\n",
      "Experiment 2 - Train Loss: 1.132909424400521, Validation Loss: 0.9733529802933423\n",
      "Experiment 3 - MSE: 1.0243383646011353, MAE: 0.8078224658966064, RMSE: 1.0120960253855042\n",
      "Experiment 3 - Train Loss: 1.1839740049365244, Validation Loss: 1.0203383520390161\n",
      "Experiment 4 - MSE: 0.9437381029129028, MAE: 0.7762559056282043, RMSE: 0.9714618381145513\n",
      "Experiment 4 - Train Loss: 1.0875967270111482, Validation Loss: 0.9400128256197842\n",
      "Experiment 5 - MSE: 1.0202438831329346, MAE: 0.8056095838546753, RMSE: 1.0100712267622192\n",
      "Experiment 5 - Train Loss: 1.2501224155315667, Validation Loss: 1.0199100833413595\n",
      "Experiment 6 - MSE: 1.0377110242843628, MAE: 0.8136131167411804, RMSE: 1.018681021853437\n",
      "Experiment 6 - Train Loss: 1.2757621965246015, Validation Loss: 1.0354095079935193\n",
      "Experiment 7 - MSE: 1.1638725996017456, MAE: 0.8482017517089844, RMSE: 1.0788292726848607\n",
      "Experiment 7 - Train Loss: 1.5968608771975237, Validation Loss: 1.1610894435578678\n",
      "Experiment 8 - MSE: 1.2185795307159424, MAE: 0.8636190295219421, RMSE: 1.1038928982088536\n",
      "Experiment 8 - Train Loss: 1.6619874518717592, Validation Loss: 1.2202325061248083\n",
      "Experiment 9 - MSE: 1.1995395421981812, MAE: 0.8572567105293274, RMSE: 1.0952349255745002\n",
      "Experiment 9 - Train Loss: 1.6531462012342844, Validation Loss: 1.2045516325388304\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(experiments) + 1):\n",
    "    print(f'Experiment {i} - MSE: {metrics[i][latest_epoch[i]][\"mse\"]}, MAE: {metrics[i][latest_epoch[i]][\"mae\"]}, RMSE: {metrics[i][latest_epoch[i]][\"rmse\"]}')\n",
    "    print(f'Experiment {i} - Train Loss: {losses[i][\"train_loss\"][-1]}, Validation Loss: {losses[i][\"val_loss\"][-1]}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9e907e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics at Minimal Validation Loss:\n",
      "Experiment 2 metrics at epoch 300: MSE: 0.974905788898468, MAE: 0.7888841032981873, RMSE: 0.9873731761084398\n",
      "Experiment 7 metrics at epoch 300: MSE: 1.1638725996017456, MAE: 0.8482017517089844, RMSE: 1.0788292726848607\n",
      "Experiment 4 metrics at epoch 300: MSE: 0.9437381029129028, MAE: 0.7762559056282043, RMSE: 0.9714618381145513\n",
      "Experiment 8 metrics at epoch 300: MSE: 1.2185795307159424, MAE: 0.8636190295219421, RMSE: 1.1038928982088536\n",
      "Experiment 1 metrics at epoch 300: MSE: 0.8298844695091248, MAE: 0.7222684621810913, RMSE: 0.910979950113681\n",
      "Experiment 6 metrics at epoch 300: MSE: 1.0377110242843628, MAE: 0.8136131167411804, RMSE: 1.018681021853437\n",
      "Experiment 3 metrics at epoch 280: MSE: 1.0382260084152222, MAE: 0.8138803243637085, RMSE: 1.018933760563081\n",
      "Experiment 9 metrics at epoch 300: MSE: 1.1995395421981812, MAE: 0.8572567105293274, RMSE: 1.0952349255745002\n",
      "Experiment 5 metrics at epoch 300: MSE: 1.0202438831329346, MAE: 0.8056095838546753, RMSE: 1.0100712267622192\n"
     ]
    }
   ],
   "source": [
    "# Function to extract the epoch with the minimal validation loss for each experiment\n",
    "def minimal_val_loss_epoch(losses):\n",
    "    min_val_loss_epochs = {}\n",
    "    for experiment_nr in losses.keys():\n",
    "        val_loss = losses[experiment_nr]['val_loss']\n",
    "        min_epoch = np.argmin(val_loss) + 1  # +1 to convert from 0-indexed to 1-indexed epoch\n",
    "        # round the epoch to nearest number % 10 == 0\n",
    "        min_epoch = round(min_epoch / 10) * 10\n",
    "        min_val_loss_epochs[experiment_nr] = min_epoch\n",
    "    return min_val_loss_epochs\n",
    "\n",
    "min_val_loss_epochs = minimal_val_loss_epoch(losses)\n",
    "\n",
    "# Function to extract the metric values at the epoch with the minimal validation loss\n",
    "def metrics_at_min_val_loss(metrics, min_val_loss_epochs):\n",
    "    metrics_at_min_val = {}\n",
    "    for experiment_nr, epoch in min_val_loss_epochs.items():\n",
    "        if epoch in metrics[experiment_nr]:\n",
    "            metrics_at_min_val[experiment_nr] = metrics[experiment_nr][epoch]\n",
    "        else:\n",
    "            print(f\"Epoch {epoch} not found for Experiment {experiment_nr}\")\n",
    "    return metrics_at_min_val\n",
    "\n",
    "metrics_min_val_loss = metrics_at_min_val_loss(metrics, min_val_loss_epochs)\n",
    "\n",
    "print(\"Metrics at Minimal Validation Loss:\")\n",
    "for experiment_nr, metric in metrics_min_val_loss.items():\n",
    "    print(f\"Experiment {experiment_nr} metrics at epoch {min_val_loss_epochs[experiment_nr]}: MSE: {metric['mse']}, MAE: {metric['mae']}, RMSE: {metric['rmse']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329cd124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot RMSE vs epsilon for each experiment, adding a horizontal line at the minimal RMSE value from the non-private experiment\n",
    "def plot_rmse_vs_epsilon(metrics, min_rmse):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    epsilons = [0.5, 0.75, 1.0, 1.25, 1.5, 2.0]\n",
    "    rmse_values = [metrics[i][100]['rmse'] for i in range(1, len(epsilons) + 1)]\n",
    "    \n",
    "    plt.plot(epsilons, rmse_values, marker='o', label='RMSE vs Epsilon')\n",
    "    plt.axhline(y=min_rmse, color='r', linestyle='--', label='Minimal RMSE (Non-Private)')\n",
    "    \n",
    "    plt.title('RMSE vs Epsilon for Different Noise Multipliers')\n",
    "    plt.xlabel('Epsilon (Noise Multiplier)')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.xticks(epsilons)\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{figure_base_path}rmse_vs_epsilon.pdf')\n",
    "    plt.close()\n",
    "\n",
    "# Calculate the minimal RMSE from the non-private experiment (experiment 1)\n",
    "min_rmse_np = 0.911\n",
    "plot_rmse_vs_epsilon(metrics, min_rmse_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4322fd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: loss vs epsilon for each experiment, adding a horizontal line at the minimal validation loss value from the non-private experiment\n",
    "def plot_loss_vs_epsilon(losses, min_val_loss_np):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    epsilons = [0.5, 0.75, 1.0, 1.25, 1.5, 2.0]\n",
    "    val_loss_values = [losses[i]['val_loss'][-1] for i in range(1, len(epsilons) + 1)]\n",
    "    \n",
    "    plt.plot(epsilons, val_loss_values, marker='o', label='Validation Loss vs Epsilon')\n",
    "    plt.axhline(y=min_val_loss_np, color='r', linestyle='--', label='Minimal Validation Loss (Non-Private)')\n",
    "    \n",
    "    plt.title('Validation Loss vs Epsilon for Different Noise Multipliers')\n",
    "    plt.xlabel('Epsilon (Noise Multiplier)')\n",
    "    plt.ylabel('Validation Loss')\n",
    "    plt.xticks(epsilons)\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{figure_base_path}loss_vs_epsilon.pdf')\n",
    "    plt.close()\n",
    "\n",
    "# Calculate the minimal validation loss from the non-private experiment (experiment 1)\n",
    "min_val_loss_np = 0.828\n",
    "plot_loss_vs_epsilon(losses, min_val_loss_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movielens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
