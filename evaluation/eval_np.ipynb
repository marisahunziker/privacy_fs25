{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9ea491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b223b995",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 6.5  # in inches\n",
    "height = width * 0.75  # 4:3 aspect ratio\n",
    "fig_size = (width, height)\n",
    "\n",
    "reds = sns.color_palette(\"Reds\", 6)\n",
    "blues = sns.color_palette(\"Blues\", 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf3121e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.005, 0.001]\n",
    "weight_decays = [1e-4, 1e-5, 1e-6]\n",
    "experiments = list(product(learning_rates, weight_decays))\n",
    "\n",
    "experiments[8]\n",
    "\n",
    "figure_base_path = \"figures/np/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb432c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15.305708271503383,\n",
       " 11.487322810368582,\n",
       " 7.942742848933449,\n",
       " 5.858235810994874,\n",
       " 4.66472411643812,\n",
       " 3.941966109525724,\n",
       " 3.4616651992613856,\n",
       " 3.129577719477014,\n",
       " 2.875642179373215,\n",
       " 2.6843750688576815,\n",
       " 2.540783216349639,\n",
       " 2.414016938100429,\n",
       " 2.3201288578907495,\n",
       " 2.2303555109800595,\n",
       " 2.156692270293118,\n",
       " 2.0978059041481463,\n",
       " 2.0355718336983006,\n",
       " 1.9921377758545518,\n",
       " 1.9456875393120843,\n",
       " 1.9070940065843895,\n",
       " 1.8686998974274334,\n",
       " 1.8324368678159284,\n",
       " 1.808341828517148,\n",
       " 1.7793228309847204,\n",
       " 1.7519605707548194,\n",
       " 1.7278026051932698,\n",
       " 1.70543632717586,\n",
       " 1.6851277958961193,\n",
       " 1.6675203908470597,\n",
       " 1.6432524844862977,\n",
       " 1.6297316877692112,\n",
       " 1.6132197006371647,\n",
       " 1.5982895172324072,\n",
       " 1.5809824688575653,\n",
       " 1.5690762218147258,\n",
       " 1.559734381784765,\n",
       " 1.5430353853762497,\n",
       " 1.5305902949586971,\n",
       " 1.5144135674881831,\n",
       " 1.5067119797501587,\n",
       " 1.4956126340965437,\n",
       " 1.4879256549607547,\n",
       " 1.472509695559674,\n",
       " 1.4687306648857976,\n",
       " 1.4583201904019796,\n",
       " 1.448916523334658,\n",
       " 1.4398699669800998,\n",
       " 1.4309331830375847,\n",
       " 1.4216390309527889,\n",
       " 1.4168143169543739,\n",
       " 1.4082868964641448,\n",
       " 1.4029836655327113,\n",
       " 1.3930572793245455,\n",
       " 1.3866947104930993,\n",
       " 1.3803536332737527,\n",
       " 1.3730220924690921,\n",
       " 1.3726116712655365,\n",
       " 1.3643483208634308,\n",
       " 1.3599731783010347,\n",
       " 1.3516888302644117,\n",
       " 1.3449319767215677,\n",
       " 1.339839242217685,\n",
       " 1.3376451439761494,\n",
       " 1.3316882899532623,\n",
       " 1.3238032669655508,\n",
       " 1.3196084585553312,\n",
       " 1.3140986273663873,\n",
       " 1.3090337488878088,\n",
       " 1.303890385906175,\n",
       " 1.2989980795132192,\n",
       " 1.2949080091789757,\n",
       " 1.2940456705828678,\n",
       " 1.2875323715357423,\n",
       " 1.2829334572601312,\n",
       " 1.2814230269393827,\n",
       " 1.27270445975633,\n",
       " 1.2734312552615847,\n",
       " 1.269862785803916,\n",
       " 1.263038592341041,\n",
       " 1.2589432707033061,\n",
       " 1.258752824216631,\n",
       " 1.2525399934568784,\n",
       " 1.250937937045781,\n",
       " 1.2475999630355008,\n",
       " 1.2435752901156323,\n",
       " 1.2410233798062467,\n",
       " 1.2371399038547428,\n",
       " 1.2334058822979386,\n",
       " 1.2315911299800824,\n",
       " 1.226661064674551,\n",
       " 1.224081165866366,\n",
       " 1.2234027701066863,\n",
       " 1.2201791271593607,\n",
       " 1.2179182069270202,\n",
       " 1.2131974523301274,\n",
       " 1.2101936706544925,\n",
       " 1.2106846919753351,\n",
       " 1.2047863567303465,\n",
       " 1.2020881656103815,\n",
       " 1.2002487868898168,\n",
       " 1.196812462104433,\n",
       " 1.1950557210177457,\n",
       " 1.1935617621054089,\n",
       " 1.1922310401850316,\n",
       " 1.1859401743527518,\n",
       " 1.184006143054462,\n",
       " 1.1834889812881766,\n",
       " 1.1811795927870448,\n",
       " 1.1770093442589566,\n",
       " 1.176164761443042,\n",
       " 1.1736463071470618,\n",
       " 1.171925748973551,\n",
       " 1.1674820275938216,\n",
       " 1.166956920252033,\n",
       " 1.1631286943708297,\n",
       " 1.159750744503139,\n",
       " 1.1584056383341506,\n",
       " 1.1565826711074731,\n",
       " 1.1528810704895156,\n",
       " 1.1523672242245084,\n",
       " 1.1491491197349593,\n",
       " 1.149215727957931,\n",
       " 1.1460583872006485,\n",
       " 1.1450980467818705,\n",
       " 1.1409907781454591,\n",
       " 1.138810157264067,\n",
       " 1.138659705754369,\n",
       " 1.1347518476492384,\n",
       " 1.1333011731852773,\n",
       " 1.1322743711958838,\n",
       " 1.1303785944576958,\n",
       " 1.1256663354859064,\n",
       " 1.1256869429676346,\n",
       " 1.1218566097078437,\n",
       " 1.1210763141888003,\n",
       " 1.1167787648151617,\n",
       " 1.1175130881561917,\n",
       " 1.1157690520857597,\n",
       " 1.1119950272444827,\n",
       " 1.1110807061559738,\n",
       " 1.107761787539655,\n",
       " 1.1050343141452865,\n",
       " 1.1009204144961025,\n",
       " 1.101386280459089,\n",
       " 1.099016816809825,\n",
       " 1.0984924209965359,\n",
       " 1.093061993716545,\n",
       " 1.0940914370879862,\n",
       " 1.0928455057132942,\n",
       " 1.088160711269109,\n",
       " 1.086217620937073,\n",
       " 1.0834118388795917,\n",
       " 1.0826402587467596,\n",
       " 1.0807108113475812,\n",
       " 1.0795557482944145,\n",
       " 1.0776334679953232,\n",
       " 1.074424932628794,\n",
       " 1.0718348207258896,\n",
       " 1.0698400964770938,\n",
       " 1.06793245364194,\n",
       " 1.0659546007788876,\n",
       " 1.0662558752280495,\n",
       " 1.0617891501814825,\n",
       " 1.0588802984632018,\n",
       " 1.0588155636001872,\n",
       " 1.0560250120934012,\n",
       " 1.05334101165921,\n",
       " 1.0516157499877354,\n",
       " 1.0491981365372907,\n",
       " 1.044866520371922,\n",
       " 1.0459627289577702,\n",
       " 1.0430935705542015,\n",
       " 1.0413443394867492,\n",
       " 1.0405929060444572,\n",
       " 1.0382740382007456,\n",
       " 1.0332819352506208,\n",
       " 1.0342521836497613,\n",
       " 1.0316292914264278,\n",
       " 1.0280944404579562,\n",
       " 1.0275855372129696,\n",
       " 1.0260801118031844,\n",
       " 1.022751703802146,\n",
       " 1.0239146611890022,\n",
       " 1.0188220289378696,\n",
       " 1.019121803426789,\n",
       " 1.0171151807730225,\n",
       " 1.0141499339304056,\n",
       " 1.0141786320894037,\n",
       " 1.0121740716388987,\n",
       " 1.0090327506954513,\n",
       " 1.0061278987508313,\n",
       " 1.005493405241731,\n",
       " 1.0021031605613115,\n",
       " 1.0028005325672957,\n",
       " 0.9993708835567814,\n",
       " 0.9981255282573127,\n",
       " 0.9982971637537071,\n",
       " 0.9971277289904719,\n",
       " 0.9938147703954348,\n",
       " 0.9919805996440944,\n",
       " 0.989243651149601,\n",
       " 0.9910663246196869,\n",
       " 0.9873546764717218,\n",
       " 0.9838575602070841,\n",
       " 0.9850007555539549,\n",
       " 0.9822668921867693,\n",
       " 0.9808918992082742,\n",
       " 0.9797206350632854,\n",
       " 0.9778408450088953,\n",
       " 0.9764787652410845,\n",
       " 0.9736965013604353,\n",
       " 0.9730027885626862,\n",
       " 0.9727747051224804,\n",
       " 0.97052900999632,\n",
       " 0.9688301403366129,\n",
       " 0.9676598059560112,\n",
       " 0.9649489545982327,\n",
       " 0.9649207512061582,\n",
       " 0.962511353987141,\n",
       " 0.9630588860517746,\n",
       " 0.9601939604769761,\n",
       " 0.9594755873074235,\n",
       " 0.958667561015016,\n",
       " 0.956191460479856,\n",
       " 0.9561637808786678,\n",
       " 0.9556335572077126,\n",
       " 0.9536036833948487,\n",
       " 0.9500186508028977,\n",
       " 0.9514271917956443,\n",
       " 0.9500486598508514,\n",
       " 0.9477218121371678,\n",
       " 0.9474876942128233,\n",
       " 0.9449159579773623,\n",
       " 0.9446758497432263,\n",
       " 0.9434226689695543,\n",
       " 0.9406692368356026,\n",
       " 0.9418019577132317,\n",
       " 0.9403247258413524,\n",
       " 0.9385508983998793,\n",
       " 0.9376439414561827,\n",
       " 0.9366228543611109,\n",
       " 0.9347271293920426,\n",
       " 0.9348310226734476,\n",
       " 0.9325168173182099,\n",
       " 0.9310697148855428,\n",
       " 0.9304494591611794,\n",
       " 0.9294663826669162,\n",
       " 0.9304374740641779,\n",
       " 0.9286567504848463,\n",
       " 0.9271300154499262,\n",
       " 0.9257421619295387,\n",
       " 0.9225081101735476,\n",
       " 0.9227975994209846,\n",
       " 0.9224018044853513,\n",
       " 0.9204754554243939,\n",
       " 0.9210373430317279,\n",
       " 0.9202281297373027,\n",
       " 0.9180433901418062,\n",
       " 0.9175710176134922,\n",
       " 0.916289048702536,\n",
       " 0.91649722173772,\n",
       " 0.9163669529182197,\n",
       " 0.9133238438855413,\n",
       " 0.9131708474010608,\n",
       " 0.9128025306563347,\n",
       " 0.9113182048884674,\n",
       " 0.9112231999017896,\n",
       " 0.9085667675048374,\n",
       " 0.909013992376823,\n",
       " 0.9076173083329561,\n",
       " 0.9071451427251598,\n",
       " 0.906969745956602,\n",
       " 0.9053982308048948,\n",
       " 0.9052703850789432,\n",
       " 0.9034897638264264,\n",
       " 0.9030959780811602,\n",
       " 0.9033614022588494,\n",
       " 0.9021291929854435,\n",
       " 0.898779866412072,\n",
       " 0.9001902646198825,\n",
       " 0.899741066834206,\n",
       " 0.8967036285991423,\n",
       " 0.8970516697395314,\n",
       " 0.896080725375335,\n",
       " 0.8949695215735588,\n",
       " 0.8954764174353549,\n",
       " 0.894492517896317,\n",
       " 0.8936206818729239,\n",
       " 0.893431384756123,\n",
       " 0.8909872715217296,\n",
       " 0.8922126146398233,\n",
       " 0.8908446012417393,\n",
       " 0.890770056509624,\n",
       " 0.8882455666522483,\n",
       " 0.8885990381969573,\n",
       " 0.8875413561136462,\n",
       " 0.8872484796153925,\n",
       " 0.8864321219830634,\n",
       " 0.885255658406542,\n",
       " 0.8843784033541316]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all loss files from ../losses/np/batchsize-128/\n",
    "# The files are expected to be in format losses_np_<experiment_nr>_epoch<epoch>.pt\n",
    "# For the non-private version, we executed 9 experiments, each with 100 epochs.\n",
    "# For now we will only load the losses at epoch 100.\n",
    "\n",
    "loss_files = glob.glob('../losses/np/14-07/losses_np_*_epoch300.pt')\n",
    "\n",
    "# Load the losses from each file and store them in a dictionary, with the experiment number as key\n",
    "losses = {}\n",
    "for file in loss_files:\n",
    "    experiment_nr = int(file.split('_')[2])  # Extract the experiment number from the filename\n",
    "    losses[experiment_nr] = torch.load(file)\n",
    "\n",
    "losses[1]['train_loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aacc56e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train_loss, validation_loss, experiment_nr):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    plt.plot(train_loss, label='Train Loss', color='blue')\n",
    "    plt.plot(validation_loss, label='Validation Loss', color='orange')\n",
    "    plt.title(f'Losses for Experiment {experiment_nr}: weight decay={experiments[experiment_nr-1][0]}, learningrate={experiments[experiment_nr-1][1]}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{figure_base_path}losses_experiment_{experiment_nr}.pdf')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "for i in range(1, 10):\n",
    "    plot_loss(losses[i]['train_loss'], losses[i]['val_loss'], i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a3322736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiment': 1,\n",
       " 'epoch': 100,\n",
       " 'mse': 0.9895796775817871,\n",
       " 'mae': 0.7962299585342407,\n",
       " 'rmse': 0.9947761947200924}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_files = glob.glob('../metrics/np/14-07/metrics_np_*_epoch*.pt')\n",
    "\n",
    "# Load the metrics from each file and store them in a dictionary, with the experiment number as key \n",
    "metrics = {}\n",
    "for file in metric_files:\n",
    "    experiment_nr = int(file.split('_')[2])  # Extract the experiment number from the filename\n",
    "    epoch = int(file.split('_')[-1].replace('epoch', '').replace('.pt', ''))  # Extract the epoch number\n",
    "    if experiment_nr not in metrics:\n",
    "        metrics[experiment_nr] = {}\n",
    "    metrics[experiment_nr][epoch] = torch.load(file, weights_only=False)\n",
    "\n",
    "metrics[1][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3dfd5211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics):\n",
    "    # Plot the metrics for a specific experiment\n",
    "    # on the x-axis we have the epochs, on the y-axis we have the metric value\n",
    "    # The metric values are mse, mae, and rmse\n",
    "    for experiment_nr in metrics.keys():\n",
    "        epochs = sorted(metrics[experiment_nr].keys())\n",
    "        mse = [metrics[experiment_nr][epoch]['mse'] for epoch in epochs]\n",
    "        mae = [metrics[experiment_nr][epoch]['mae'] for epoch in epochs]\n",
    "        plt.figure(figsize=fig_size)\n",
    "        plt.plot(epochs, mse, label='MSE', color='blue')\n",
    "        plt.plot(epochs, mae, label='MAE', color='orange')\n",
    "        plt.title(f'Metrics for Experiment {experiment_nr}: weight decay={experiments[experiment_nr-1][0]}, learningrate={experiments[experiment_nr-1][1]}')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Metric Value')\n",
    "        plt.legend()\n",
    "        plt.savefig(f'{figure_base_path}metrics_experiment_{experiment_nr}.pdf')\n",
    "        plt.close()\n",
    "\n",
    "    \n",
    "\n",
    "plot_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b89600a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([3, 1, 9, 4, 2, 7, 8, 6, 5])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_mse(metrics):\n",
    "    # Plot the MSE for all experiments\n",
    "    plt.figure(figsize=fig_size)\n",
    "    for experiment_nr in metrics.keys():\n",
    "        epochs = sorted(metrics[experiment_nr].keys())\n",
    "        mse = [metrics[experiment_nr][epoch]['mse'] for epoch in epochs]\n",
    "        plt.plot(epochs, mse, label=f'Experiment {experiment_nr}')\n",
    "    plt.title('MSE for All Experiments')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{figure_base_path}mse_all_experiments.pdf')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "metrics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "34b8efe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal MSE: 0.8298844695091248 in Experiment 1\n",
      "Minimal MAE: 0.7222684621810913 in Experiment 1\n",
      "Minimal RMSE: 0.910979950113681 in Experiment 1\n"
     ]
    }
   ],
   "source": [
    "# Experiment with the minimal metric values \n",
    "def minimal_metrics(metrics):\n",
    "    # Find the experiment number with the minimal MSE, MAE, and RMSE at epoch 100\n",
    "    min_mse = float('inf')\n",
    "    min_mae = float('inf')\n",
    "    min_rmse = float('inf')\n",
    "    min_mse_experiment = None\n",
    "    min_mae_experiment = None\n",
    "    min_rmse_experiment = None\n",
    "    for experiment_nr in metrics.keys():\n",
    "        mse = metrics[experiment_nr][300]['mse']\n",
    "        mae = metrics[experiment_nr][300]['mae']\n",
    "        rmse = metrics[experiment_nr][300]['rmse']\n",
    "        if mse < min_mse:\n",
    "            min_mse = mse\n",
    "            min_mse_experiment = experiment_nr\n",
    "        if mae < min_mae:\n",
    "            min_mae = mae\n",
    "            min_mae_experiment = experiment_nr\n",
    "        if rmse < min_rmse:\n",
    "            min_rmse = rmse\n",
    "            min_rmse_experiment = experiment_nr\n",
    "    print(f'Minimal MSE: {min_mse} in Experiment {min_mse_experiment}')\n",
    "    print(f'Minimal MAE: {min_mae} in Experiment {min_mae_experiment}')\n",
    "    print(f'Minimal RMSE: {min_rmse} in Experiment {min_rmse_experiment}')\n",
    "\n",
    "minimal_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f5cd494a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal Train Loss: 0.8843784033541316 in Experiment 1\n",
      "Minimal Validation Loss: 0.8281576169557989 in Experiment 1\n"
     ]
    }
   ],
   "source": [
    "def minimal_loss(losses):\n",
    "    # Find the experiment number with the minimal train and validation loss at epoch 100\n",
    "    min_train_loss = float('inf')\n",
    "    min_val_loss = float('inf')\n",
    "    min_train_loss_experiment = None\n",
    "    min_val_loss_experiment = None\n",
    "    for experiment_nr in losses.keys():\n",
    "        train_loss = losses[experiment_nr]['train_loss'][-1]  # Last value is at epoch 100\n",
    "        val_loss = losses[experiment_nr]['val_loss'][-1]  # Last value is at epoch 100\n",
    "        if train_loss < min_train_loss:\n",
    "            min_train_loss = train_loss\n",
    "            min_train_loss_experiment = experiment_nr\n",
    "        if val_loss < min_val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            min_val_loss_experiment = experiment_nr\n",
    "    print(f'Minimal Train Loss: {min_train_loss} in Experiment {min_train_loss_experiment}')\n",
    "    print(f'Minimal Validation Loss: {min_val_loss} in Experiment {min_val_loss_experiment}')\n",
    "\n",
    "minimal_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e0964269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1 - MSE: 0.8298844695091248, MAE: 0.7222684621810913, RMSE: 0.910979950113681\n",
      "Experiment 1 - Train Loss: 0.8843784033541316, Validation Loss: 0.8281576169557989\n",
      "Experiment 2 - MSE: 0.974905788898468, MAE: 0.7888841032981873, RMSE: 0.9873731761084398\n",
      "Experiment 2 - Train Loss: 1.132909424400521, Validation Loss: 0.9733529802933423\n",
      "Experiment 3 - MSE: 1.0243383646011353, MAE: 0.8078224658966064, RMSE: 1.0120960253855042\n",
      "Experiment 3 - Train Loss: 1.1839740049365244, Validation Loss: 1.0203383520390161\n",
      "Experiment 4 - MSE: 0.9437381029129028, MAE: 0.7762559056282043, RMSE: 0.9714618381145513\n",
      "Experiment 4 - Train Loss: 1.0875967270111482, Validation Loss: 0.9400128256197842\n",
      "Experiment 5 - MSE: 1.0202438831329346, MAE: 0.8056095838546753, RMSE: 1.0100712267622192\n",
      "Experiment 5 - Train Loss: 1.2501224155315667, Validation Loss: 1.0199100833413595\n",
      "Experiment 6 - MSE: 1.0377110242843628, MAE: 0.8136131167411804, RMSE: 1.018681021853437\n",
      "Experiment 6 - Train Loss: 1.2757621965246015, Validation Loss: 1.0354095079935193\n",
      "Experiment 7 - MSE: 1.1638725996017456, MAE: 0.8482017517089844, RMSE: 1.0788292726848607\n",
      "Experiment 7 - Train Loss: 1.5968608771975237, Validation Loss: 1.1610894435578678\n",
      "Experiment 8 - MSE: 1.2185795307159424, MAE: 0.8636190295219421, RMSE: 1.1038928982088536\n",
      "Experiment 8 - Train Loss: 1.6619874518717592, Validation Loss: 1.2202325061248083\n",
      "Experiment 9 - MSE: 1.1995395421981812, MAE: 0.8572567105293274, RMSE: 1.0952349255745002\n",
      "Experiment 9 - Train Loss: 1.6531462012342844, Validation Loss: 1.2045516325388304\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    print(f'Experiment {i} - MSE: {metrics[i][300][\"mse\"]}, MAE: {metrics[i][300][\"mae\"]}, RMSE: {metrics[i][300][\"rmse\"]}')\n",
    "    print(f'Experiment {i} - Train Loss: {losses[i][\"train_loss\"][-1]}, Validation Loss: {losses[i][\"val_loss\"][-1]}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5a9e907e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics at Minimal Validation Loss:\n",
      "Experiment 2 metrics at epoch 300: MSE: 0.974905788898468, MAE: 0.7888841032981873, RMSE: 0.9873731761084398\n",
      "Experiment 7 metrics at epoch 300: MSE: 1.1638725996017456, MAE: 0.8482017517089844, RMSE: 1.0788292726848607\n",
      "Experiment 4 metrics at epoch 300: MSE: 0.9437381029129028, MAE: 0.7762559056282043, RMSE: 0.9714618381145513\n",
      "Experiment 8 metrics at epoch 300: MSE: 1.2185795307159424, MAE: 0.8636190295219421, RMSE: 1.1038928982088536\n",
      "Experiment 1 metrics at epoch 300: MSE: 0.8298844695091248, MAE: 0.7222684621810913, RMSE: 0.910979950113681\n",
      "Experiment 6 metrics at epoch 300: MSE: 1.0377110242843628, MAE: 0.8136131167411804, RMSE: 1.018681021853437\n",
      "Experiment 3 metrics at epoch 280: MSE: 1.0382260084152222, MAE: 0.8138803243637085, RMSE: 1.018933760563081\n",
      "Experiment 9 metrics at epoch 300: MSE: 1.1995395421981812, MAE: 0.8572567105293274, RMSE: 1.0952349255745002\n",
      "Experiment 5 metrics at epoch 300: MSE: 1.0202438831329346, MAE: 0.8056095838546753, RMSE: 1.0100712267622192\n"
     ]
    }
   ],
   "source": [
    "# Function to extract the epoch with the minimal validation loss for each experiment\n",
    "def minimal_val_loss_epoch(losses):\n",
    "    min_val_loss_epochs = {}\n",
    "    for experiment_nr in losses.keys():\n",
    "        val_loss = losses[experiment_nr]['val_loss']\n",
    "        min_epoch = np.argmin(val_loss) + 1  # +1 to convert from 0-indexed to 1-indexed epoch\n",
    "        # round the epoch to nearest number % 10 == 0\n",
    "        min_epoch = round(min_epoch / 10) * 10\n",
    "        min_val_loss_epochs[experiment_nr] = min_epoch\n",
    "    return min_val_loss_epochs\n",
    "\n",
    "min_val_loss_epochs = minimal_val_loss_epoch(losses)\n",
    "\n",
    "# Function to extract the metric values at the epoch with the minimal validation loss\n",
    "def metrics_at_min_val_loss(metrics, min_val_loss_epochs):\n",
    "    metrics_at_min_val = {}\n",
    "    for experiment_nr, epoch in min_val_loss_epochs.items():\n",
    "        if epoch in metrics[experiment_nr]:\n",
    "            metrics_at_min_val[experiment_nr] = metrics[experiment_nr][epoch]\n",
    "        else:\n",
    "            print(f\"Epoch {epoch} not found for Experiment {experiment_nr}\")\n",
    "    return metrics_at_min_val\n",
    "\n",
    "metrics_min_val_loss = metrics_at_min_val_loss(metrics, min_val_loss_epochs)\n",
    "\n",
    "print(\"Metrics at Minimal Validation Loss:\")\n",
    "for experiment_nr, metric in metrics_min_val_loss.items():\n",
    "    print(f\"Experiment {experiment_nr} metrics at epoch {min_val_loss_epochs[experiment_nr]}: MSE: {metric['mse']}, MAE: {metric['mae']}, RMSE: {metric['rmse']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b95511bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{135: {'epoch': 135,\n",
       "  'mse': 1.221663236618042,\n",
       "  'mae': 0.8623573184013367,\n",
       "  'rmse': 1.1052887571209806},\n",
       " 70: {'epoch': 70,\n",
       "  'mse': 1.940195083618164,\n",
       "  'mae': 1.0398714542388916,\n",
       "  'rmse': 1.3929088568955845},\n",
       " 150: {'epoch': 150,\n",
       "  'mse': 1.171414852142334,\n",
       "  'mae': 0.848261833190918,\n",
       "  'rmse': 1.0823192006715643},\n",
       " 290: {'epoch': 290,\n",
       "  'mse': 1.0130935907363892,\n",
       "  'mae': 0.79815673828125,\n",
       "  'rmse': 1.0065255042652368},\n",
       " 280: {'epoch': 280,\n",
       "  'mse': 1.0178463459014893,\n",
       "  'mae': 0.7998907566070557,\n",
       "  'rmse': 1.0088837127744155},\n",
       " 140: {'epoch': 140,\n",
       "  'mse': 1.2030935287475586,\n",
       "  'mae': 0.8571821451187134,\n",
       "  'rmse': 1.0968562024019186},\n",
       " 60: {'epoch': 60,\n",
       "  'mse': 2.280853509902954,\n",
       "  'mae': 1.1157478094100952,\n",
       "  'rmse': 1.510249485980033},\n",
       " 125: {'epoch': 125,\n",
       "  'mse': 1.2659857273101807,\n",
       "  'mae': 0.8744534254074097,\n",
       "  'rmse': 1.1251603118267994},\n",
       " 105: {'epoch': 105,\n",
       "  'mse': 1.3966084718704224,\n",
       "  'mae': 0.9089094400405884,\n",
       "  'rmse': 1.1817819053744318},\n",
       " 160: {'epoch': 160,\n",
       "  'mse': 1.1456266641616821,\n",
       "  'mae': 0.8408196568489075,\n",
       "  'rmse': 1.0703395088296432},\n",
       " 170: {'epoch': 170,\n",
       "  'mse': 1.1241841316223145,\n",
       "  'mae': 0.8344064354896545,\n",
       "  'rmse': 1.06027549798263},\n",
       " 50: {'epoch': 50,\n",
       "  'mse': 2.83147931098938,\n",
       "  'mae': 1.2327488660812378,\n",
       "  'rmse': 1.6827000062368158},\n",
       " 115: {'epoch': 115,\n",
       "  'mse': 1.3228744268417358,\n",
       "  'mae': 0.8896961212158203,\n",
       "  'rmse': 1.1501627827580476},\n",
       " 295: {'epoch': 295,\n",
       "  'mse': 1.0108774900436401,\n",
       "  'mae': 0.7973290681838989,\n",
       "  'rmse': 1.0054240349442816},\n",
       " 155: {'epoch': 155,\n",
       "  'mse': 1.1578340530395508,\n",
       "  'mae': 0.8443555235862732,\n",
       "  'rmse': 1.0760269759813417},\n",
       " 75: {'epoch': 75,\n",
       "  'mse': 1.8161431550979614,\n",
       "  'mae': 1.0112706422805786,\n",
       "  'rmse': 1.3476435563968543},\n",
       " 130: {'epoch': 130,\n",
       "  'mse': 1.242599606513977,\n",
       "  'mae': 0.8681344389915466,\n",
       "  'rmse': 1.1147195192127826},\n",
       " 120: {'epoch': 120,\n",
       "  'mse': 1.292750597000122,\n",
       "  'mae': 0.8817340135574341,\n",
       "  'rmse': 1.136991907183214},\n",
       " 65: {'epoch': 65,\n",
       "  'mse': 2.0918869972229004,\n",
       "  'mae': 1.0740985870361328,\n",
       "  'rmse': 1.44633571387244},\n",
       " 145: {'epoch': 145,\n",
       "  'mse': 1.1864454746246338,\n",
       "  'mae': 0.8525219559669495,\n",
       "  'rmse': 1.0892407789945406},\n",
       " 285: {'epoch': 285,\n",
       "  'mse': 1.015386700630188,\n",
       "  'mae': 0.7990006804466248,\n",
       "  'rmse': 1.0076639820050075},\n",
       " 165: {'epoch': 165,\n",
       "  'mse': 1.1343713998794556,\n",
       "  'mae': 0.8374730944633484,\n",
       "  'rmse': 1.0650687301200124},\n",
       " 100: {'epoch': 100,\n",
       "  'mse': 1.441980242729187,\n",
       "  'mae': 0.9205175638198853,\n",
       "  'rmse': 1.2008248176687502},\n",
       " 110: {'epoch': 110,\n",
       "  'mse': 1.357198715209961,\n",
       "  'mae': 0.8987017869949341,\n",
       "  'rmse': 1.1649887189196129},\n",
       " 55: {'epoch': 55,\n",
       "  'mse': 2.5207390785217285,\n",
       "  'mae': 1.167467474937439,\n",
       "  'rmse': 1.5876835574262675},\n",
       " 175: {'epoch': 175,\n",
       "  'mse': 1.1148818731307983,\n",
       "  'mae': 0.8315975069999695,\n",
       "  'rmse': 1.05587966792187},\n",
       " 265: {'epoch': 265,\n",
       "  'mse': 1.0257755517959595,\n",
       "  'mae': 0.8027600049972534,\n",
       "  'rmse': 1.0128057818732867},\n",
       " 85: {'epoch': 85,\n",
       "  'mse': 1.6281780004501343,\n",
       "  'mae': 0.9665871262550354,\n",
       "  'rmse': 1.2760007838752037},\n",
       " 200: {'epoch': 200,\n",
       "  'mse': 1.0784810781478882,\n",
       "  'mae': 0.8203372359275818,\n",
       "  'rmse': 1.0384994357956523},\n",
       " 210: {'epoch': 210,\n",
       "  'mse': 1.0673373937606812,\n",
       "  'mae': 0.816766619682312,\n",
       "  'rmse': 1.0331202223171712},\n",
       " 95: {'epoch': 95,\n",
       "  'mse': 1.494564414024353,\n",
       "  'mae': 0.9337590932846069,\n",
       "  'rmse': 1.222523788735562},\n",
       " 275: {'epoch': 275,\n",
       "  'mse': 1.020357370376587,\n",
       "  'mae': 0.8008178472518921,\n",
       "  'rmse': 1.0101274030421048},\n",
       " 255: {'epoch': 255,\n",
       "  'mse': 1.0316170454025269,\n",
       "  'mae': 0.8048155903816223,\n",
       "  'rmse': 1.015685505165121},\n",
       " 195: {'epoch': 195,\n",
       "  'mse': 1.0846494436264038,\n",
       "  'mae': 0.822253406047821,\n",
       "  'rmse': 1.041465046761726},\n",
       " 230: {'epoch': 230,\n",
       "  'mse': 1.0491796731948853,\n",
       "  'mae': 0.810827910900116,\n",
       "  'rmse': 1.0242947198901717},\n",
       " 220: {'epoch': 220,\n",
       "  'mse': 1.057659387588501,\n",
       "  'mae': 0.8136447072029114,\n",
       "  'rmse': 1.0284256840377437},\n",
       " 185: {'epoch': 185,\n",
       "  'mse': 1.0985711812973022,\n",
       "  'mae': 0.8266369104385376,\n",
       "  'rmse': 1.048127464241493},\n",
       " 245: {'epoch': 245,\n",
       "  'mse': 1.0380092859268188,\n",
       "  'mae': 0.8070052266120911,\n",
       "  'rmse': 1.018827407330024},\n",
       " 80: {'epoch': 80,\n",
       "  'mse': 1.713883876800537,\n",
       "  'mae': 0.987183690071106,\n",
       "  'rmse': 1.3091538781978753},\n",
       " 205: {'epoch': 205,\n",
       "  'mse': 1.0727379322052002,\n",
       "  'mae': 0.8184984922409058,\n",
       "  'rmse': 1.0357306272410796},\n",
       " 260: {'epoch': 260,\n",
       "  'mse': 1.0285676717758179,\n",
       "  'mae': 0.8037281036376953,\n",
       "  'rmse': 1.0141832535473152},\n",
       " 270: {'epoch': 270,\n",
       "  'mse': 1.0229429006576538,\n",
       "  'mae': 0.8016992807388306,\n",
       "  'rmse': 1.0114063973782517},\n",
       " 215: {'epoch': 215,\n",
       "  'mse': 1.062379002571106,\n",
       "  'mae': 0.8151856660842896,\n",
       "  'rmse': 1.03071771235926},\n",
       " 90: {'epoch': 90,\n",
       "  'mse': 1.5559362173080444,\n",
       "  'mae': 0.9489917159080505,\n",
       "  'rmse': 1.247371723788881},\n",
       " 235: {'epoch': 235,\n",
       "  'mse': 1.045262336730957,\n",
       "  'mae': 0.8094801306724548,\n",
       "  'rmse': 1.0223807200504893},\n",
       " 190: {'epoch': 190,\n",
       "  'mse': 1.0912165641784668,\n",
       "  'mae': 0.8243042826652527,\n",
       "  'rmse': 1.0446131169856459},\n",
       " 250: {'epoch': 250,\n",
       "  'mse': 1.034725308418274,\n",
       "  'mae': 0.8058741092681885,\n",
       "  'rmse': 1.0172144849628686},\n",
       " 240: {'epoch': 240,\n",
       "  'mse': 1.0416899919509888,\n",
       "  'mae': 0.8083036541938782,\n",
       "  'rmse': 1.020632153104628},\n",
       " 300: {'epoch': 300,\n",
       "  'mse': 1.0087087154388428,\n",
       "  'mae': 0.7965339422225952,\n",
       "  'rmse': 1.0043449185607716},\n",
       " 180: {'epoch': 180,\n",
       "  'mse': 1.1064270734786987,\n",
       "  'mae': 0.8290517330169678,\n",
       "  'rmse': 1.0518683726962699},\n",
       " 225: {'epoch': 225,\n",
       "  'mse': 1.0532476902008057,\n",
       "  'mae': 0.8121581673622131,\n",
       "  'rmse': 1.026278563646735}}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses_no_metadata = torch.load('../losses/np/14-07/no-metadata/losses_np_no_metadata_epoch300.pt')\n",
    "metric_files_no_metadata = glob.glob('../metrics/np/14-07/no-metadata/metrics_np_*_epoch*.pt')\n",
    "\n",
    "# Load the metrics from each file and store them in a dictionary, with the experiment number as key \n",
    "metrics_no_metadata = {}\n",
    "for file in metric_files_no_metadata:\n",
    "    epoch = int(file.split('_')[-1].replace('epoch', '').replace('.pt', ''))  # Extract the epoch number\n",
    "    metrics_no_metadata[epoch] = torch.load(file, weights_only=False)\n",
    "\n",
    "metrics_no_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dca19d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_no_metadata(metrics):\n",
    "    # Plot the metrics for the no metadata experiment\n",
    "    epochs = sorted(metrics.keys())\n",
    "    mse = [metrics[epoch]['mse'] for epoch in epochs]\n",
    "    mae = [metrics[epoch]['mae'] for epoch in epochs]\n",
    "    plt.figure(figsize=fig_size)\n",
    "    plt.plot(epochs, mse, label='MSE', color='blue')\n",
    "    plt.plot(epochs, mae, label='MAE', color='orange')\n",
    "    plt.title('Metrics for No Metadata Experiment')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Metric Value')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{figure_base_path}metrics_no_metadata.pdf')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "plot_metrics_no_metadata(metrics_no_metadata)\n",
    "\n",
    "\n",
    "def plot_loss_no_metadata(losses):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    plt.plot(losses['train_loss'], label='Train Loss', color='blue')\n",
    "    plt.plot(losses['val_loss'], label='Validation Loss', color='orange')\n",
    "    plt.title('Losses for No Metadata Experiment')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{figure_base_path}losses_no_metadata.pdf')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "plot_loss_no_metadata(losses_no_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "36eab7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Experiment      RMSE       MSE       MAE\n",
      "0            1  0.910980  0.829884  0.722268\n",
      "1  No Metadata  1.004345  1.008709  0.796534\n"
     ]
    }
   ],
   "source": [
    "# Compare the metrics of the no metadata experiment with the results from the best experiment including metadata\n",
    "def compare_metrics(metrics, metrics_no_metadata, best_experiment):\n",
    "    # Get the metrics for the best experiment\n",
    "    best_metrics = metrics[best_experiment][300]\n",
    "    mse_best = best_metrics['mse']\n",
    "    mae_best = best_metrics['mae']\n",
    "    rmse_best = best_metrics['rmse']\n",
    "    \n",
    "    # Get the metrics for the no metadata experiment at epoch 100\n",
    "    mse_no_metadata = metrics_no_metadata[300]['mse']\n",
    "    mae_no_metadata = metrics_no_metadata[300]['mae']\n",
    "    \n",
    "    # Create a DataFrame for comparison\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Experiment': ['1', 'No Metadata'],\n",
    "        'RMSE': [rmse_best, metrics_no_metadata[300]['rmse']],\n",
    "        'MSE': [mse_best, mse_no_metadata],\n",
    "        'MAE': [mae_best, mae_no_metadata]\n",
    "    })\n",
    "    \n",
    "    print(comparison_df)\n",
    "\n",
    "compare_metrics(metrics, metrics_no_metadata, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "659e861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation losses of the no metadata experiment with the best experiment including metadata\n",
    "def plot_comparison_loss(losses, losses_no_metadata, best_experiment):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    \n",
    "    # Plot the best experiment\n",
    "    plt.plot(losses[best_experiment]['train_loss'], label='Train Loss (Best Experiment)', color='blue')\n",
    "    plt.plot(losses[best_experiment]['val_loss'], label='Validation Loss (Best Experiment)', color='orange')\n",
    "    \n",
    "    # Plot the no metadata experiment\n",
    "    plt.plot(losses_no_metadata['train_loss'], label='Train Loss (No Metadata)', color='blue', linestyle='--')\n",
    "    plt.plot(losses_no_metadata['val_loss'], label='Validation Loss (No Metadata)', color='orange', linestyle='--')\n",
    "    \n",
    "    plt.title('Comparison of Losses: Best Experiment vs No Metadata')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{figure_base_path}comparison_losses.pdf')\n",
    "    plt.close()\n",
    "\n",
    "plot_comparison_loss(losses, losses_no_metadata, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aa7caf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation losses of the no metadata experiment with the best experiment including metadata\n",
    "def plot_comparison_loss(losses, losses_no_metadata, best_experiment):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    \n",
    "    # Only plot the last 100 epochs\n",
    "    train_loss_best = losses[best_experiment]['train_loss'][-100:]\n",
    "    val_loss_best = losses[best_experiment]['val_loss'][-100:]\n",
    "    train_loss_no_metadata = losses_no_metadata['train_loss'][-100:]\n",
    "    val_loss_no_metadata = losses_no_metadata['val_loss'][-100:]\n",
    "    epochs = range(len(losses[best_experiment]['train_loss']) - 99, len(losses[best_experiment]['train_loss']) + 1)\n",
    "    \n",
    "    plt.plot(epochs, train_loss_best, label='Train Loss (Best Experiment)', color='blue')\n",
    "    plt.plot(epochs, val_loss_best, label='Validation Loss (Best Experiment)', color='orange')\n",
    "    plt.plot(epochs, train_loss_no_metadata, label='Train Loss (No Metadata)', color='blue', linestyle='--')\n",
    "    plt.plot(epochs, val_loss_no_metadata, label='Validation Loss (No Metadata)', color='orange', linestyle='--')\n",
    "    \n",
    "    plt.title('Comparison of Losses (Last 100 Epochs): Best Experiment vs No Metadata')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{figure_base_path}comparison_losses_last100.pdf')\n",
    "    plt.close()\n",
    "\n",
    "plot_comparison_loss(losses, losses_no_metadata, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831be106",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movielens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
