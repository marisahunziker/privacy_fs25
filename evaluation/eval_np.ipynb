{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9ea491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import glob\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d7325e",
   "metadata": {},
   "source": [
    "# Evaluation of Non-Private Models\n",
    "\n",
    "This script can be used to analyze and plot the metrics and losses gather during the training of the non-private models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b223b995",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 6.5  # in inches\n",
    "height = width * 0.75  # 4:3 aspect ratio\n",
    "fig_size = (width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf3121e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.005, 0.001]\n",
    "weight_decays = [1e-4, 1e-5, 1e-6]\n",
    "experiments = list(product(learning_rates, weight_decays))\n",
    "\n",
    "experiments[8]\n",
    "\n",
    "figure_base_path = \"figures/np/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb432c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_files = glob.glob('../losses/np/losses_np_*_epoch300.pt')\n",
    "\n",
    "# Load the losses from each file and store them in a dictionary, with the experiment number as key\n",
    "losses = {}\n",
    "for file in loss_files:\n",
    "    experiment_nr = int(file.split('_')[2])  # Extract the experiment number from the filename\n",
    "    losses[experiment_nr] = torch.load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aacc56e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train_loss, validation_loss, experiment_nr):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    plt.plot(train_loss, label='Train Loss', color='blue')\n",
    "    plt.plot(validation_loss, label='Validation Loss', color='orange', linestyle='--')\n",
    "    plt.title(f'Losses for Experiment {experiment_nr}: weight decay={experiments[experiment_nr-1][0]}, learningrate={experiments[experiment_nr-1][1]}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{figure_base_path}losses_experiment_{experiment_nr}.pdf')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "for i in range(1, 10):\n",
    "    plot_loss(losses[i]['train_loss'], losses[i]['val_loss'], i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3322736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiment': 1,\n",
       " 'epoch': 100,\n",
       " 'mse': 0.9895796775817871,\n",
       " 'mae': 0.7962299585342407,\n",
       " 'rmse': 0.9947761947200924}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_files = glob.glob('../metrics/np/metrics_np_*_epoch*.pt')\n",
    "\n",
    "# Load the metrics from each file and store them in a dictionary, with the experiment number as key \n",
    "metrics = {}\n",
    "for file in metric_files:\n",
    "    experiment_nr = int(file.split('_')[2])  # Extract the experiment number from the filename\n",
    "    epoch = int(file.split('_')[-1].replace('epoch', '').replace('.pt', ''))  # Extract the epoch number\n",
    "    if experiment_nr not in metrics:\n",
    "        metrics[experiment_nr] = {}\n",
    "    metrics[experiment_nr][epoch] = torch.load(file, weights_only=False)\n",
    "\n",
    "metrics[1][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3dfd5211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics):\n",
    "    # Plot the metrics for a specific experiment\n",
    "    # on the x-axis we have the epochs, on the y-axis we have the metric value\n",
    "    # The metric values are mse, mae, and rmse\n",
    "    for experiment_nr in metrics.keys():\n",
    "        epochs = sorted(metrics[experiment_nr].keys())\n",
    "        mse = [metrics[experiment_nr][epoch]['mse'] for epoch in epochs]\n",
    "        mae = [metrics[experiment_nr][epoch]['mae'] for epoch in epochs]\n",
    "        plt.figure(figsize=fig_size)\n",
    "        plt.plot(epochs, mse, label='MSE', color='blue')\n",
    "        plt.plot(epochs, mae, label='MAE', color='orange')\n",
    "        plt.title(f'Metrics for Experiment {experiment_nr}: weight decay={experiments[experiment_nr-1][0]}, learningrate={experiments[experiment_nr-1][1]}')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Metric Value')\n",
    "        plt.legend()\n",
    "        ax = plt.gca()\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        plt.savefig(f'{figure_base_path}metrics_experiment_{experiment_nr}.pdf')\n",
    "        plt.close()\n",
    "\n",
    "    \n",
    "\n",
    "plot_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b89600a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([3, 1, 9, 4, 2, 7, 8, 6, 5])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_mse(metrics):\n",
    "    # Plot the MSE for all experiments\n",
    "    plt.figure(figsize=fig_size)\n",
    "    for experiment_nr in metrics.keys():\n",
    "        epochs = sorted(metrics[experiment_nr].keys())\n",
    "        mse = [metrics[experiment_nr][epoch]['mse'] for epoch in epochs]\n",
    "        plt.plot(epochs, mse, label=f'Experiment {experiment_nr}')\n",
    "    plt.title('MSE for All Experiments')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend()\n",
    "    ax = plt.gca()\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    plt.savefig(f'{figure_base_path}mse_all_experiments.pdf')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "metrics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34b8efe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal MSE: 0.8298844695091248 in Experiment 1\n",
      "Minimal MAE: 0.7222684621810913 in Experiment 1\n",
      "Minimal RMSE: 0.910979950113681 in Experiment 1\n"
     ]
    }
   ],
   "source": [
    "# Find the experiment with the minimal metric values \n",
    "def minimal_metrics(metrics):\n",
    "    # Find the experiment number with the minimal MSE, MAE, and RMSE at epoch 300\n",
    "    min_mse = float('inf')\n",
    "    min_mae = float('inf')\n",
    "    min_rmse = float('inf')\n",
    "    min_mse_experiment = None\n",
    "    min_mae_experiment = None\n",
    "    min_rmse_experiment = None\n",
    "    for experiment_nr in metrics.keys():\n",
    "        mse = metrics[experiment_nr][300]['mse']\n",
    "        mae = metrics[experiment_nr][300]['mae']\n",
    "        rmse = metrics[experiment_nr][300]['rmse']\n",
    "        if mse < min_mse:\n",
    "            min_mse = mse\n",
    "            min_mse_experiment = experiment_nr\n",
    "        if mae < min_mae:\n",
    "            min_mae = mae\n",
    "            min_mae_experiment = experiment_nr\n",
    "        if rmse < min_rmse:\n",
    "            min_rmse = rmse\n",
    "            min_rmse_experiment = experiment_nr\n",
    "    print(f'Minimal MSE: {min_mse} in Experiment {min_mse_experiment}')\n",
    "    print(f'Minimal MAE: {min_mae} in Experiment {min_mae_experiment}')\n",
    "    print(f'Minimal RMSE: {min_rmse} in Experiment {min_rmse_experiment}')\n",
    "\n",
    "minimal_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5cd494a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal Train Loss: 0.8843784033541316 in Experiment 1\n",
      "Minimal Validation Loss: 0.8281576169557989 in Experiment 1\n"
     ]
    }
   ],
   "source": [
    "def minimal_loss(losses):\n",
    "    # Find the experiment number with the minimal train and validation loss at epoch 300\n",
    "    min_train_loss = float('inf')\n",
    "    min_val_loss = float('inf')\n",
    "    min_train_loss_experiment = None\n",
    "    min_val_loss_experiment = None\n",
    "    for experiment_nr in losses.keys():\n",
    "        train_loss = losses[experiment_nr]['train_loss'][-1]  # Last value is at epoch 300\n",
    "        val_loss = losses[experiment_nr]['val_loss'][-1]  # Last value is at epoch 300\n",
    "        if train_loss < min_train_loss:\n",
    "            min_train_loss = train_loss\n",
    "            min_train_loss_experiment = experiment_nr\n",
    "        if val_loss < min_val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            min_val_loss_experiment = experiment_nr\n",
    "    print(f'Minimal Train Loss: {min_train_loss} in Experiment {min_train_loss_experiment}')\n",
    "    print(f'Minimal Validation Loss: {min_val_loss} in Experiment {min_val_loss_experiment}')\n",
    "\n",
    "minimal_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0964269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1 - MSE: 0.8298844695091248, MAE: 0.7222684621810913, RMSE: 0.910979950113681\n",
      "Experiment 1 - Train Loss: 0.8843784033541316, Validation Loss: 0.8281576169557989\n",
      "Experiment 2 - MSE: 0.974905788898468, MAE: 0.7888841032981873, RMSE: 0.9873731761084398\n",
      "Experiment 2 - Train Loss: 1.132909424400521, Validation Loss: 0.9733529802933423\n",
      "Experiment 3 - MSE: 1.0243383646011353, MAE: 0.8078224658966064, RMSE: 1.0120960253855042\n",
      "Experiment 3 - Train Loss: 1.1839740049365244, Validation Loss: 1.0203383520390161\n",
      "Experiment 4 - MSE: 0.9437381029129028, MAE: 0.7762559056282043, RMSE: 0.9714618381145513\n",
      "Experiment 4 - Train Loss: 1.0875967270111482, Validation Loss: 0.9400128256197842\n",
      "Experiment 5 - MSE: 1.0202438831329346, MAE: 0.8056095838546753, RMSE: 1.0100712267622192\n",
      "Experiment 5 - Train Loss: 1.2501224155315667, Validation Loss: 1.0199100833413595\n",
      "Experiment 6 - MSE: 1.0377110242843628, MAE: 0.8136131167411804, RMSE: 1.018681021853437\n",
      "Experiment 6 - Train Loss: 1.2757621965246015, Validation Loss: 1.0354095079935193\n",
      "Experiment 7 - MSE: 1.1638725996017456, MAE: 0.8482017517089844, RMSE: 1.0788292726848607\n",
      "Experiment 7 - Train Loss: 1.5968608771975237, Validation Loss: 1.1610894435578678\n",
      "Experiment 8 - MSE: 1.2185795307159424, MAE: 0.8636190295219421, RMSE: 1.1038928982088536\n",
      "Experiment 8 - Train Loss: 1.6619874518717592, Validation Loss: 1.2202325061248083\n",
      "Experiment 9 - MSE: 1.1995395421981812, MAE: 0.8572567105293274, RMSE: 1.0952349255745002\n",
      "Experiment 9 - Train Loss: 1.6531462012342844, Validation Loss: 1.2045516325388304\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    print(f'Experiment {i} - MSE: {metrics[i][300][\"mse\"]}, MAE: {metrics[i][300][\"mae\"]}, RMSE: {metrics[i][300][\"rmse\"]}')\n",
    "    print(f'Experiment {i} - Train Loss: {losses[i][\"train_loss\"][-1]}, Validation Loss: {losses[i][\"val_loss\"][-1]}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a9e907e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics at Minimal Validation Loss:\n",
      "Experiment 2 metrics at epoch 300: MSE: 0.974905788898468, MAE: 0.7888841032981873, RMSE: 0.9873731761084398\n",
      "Experiment 7 metrics at epoch 300: MSE: 1.1638725996017456, MAE: 0.8482017517089844, RMSE: 1.0788292726848607\n",
      "Experiment 4 metrics at epoch 300: MSE: 0.9437381029129028, MAE: 0.7762559056282043, RMSE: 0.9714618381145513\n",
      "Experiment 8 metrics at epoch 300: MSE: 1.2185795307159424, MAE: 0.8636190295219421, RMSE: 1.1038928982088536\n",
      "Experiment 1 metrics at epoch 300: MSE: 0.8298844695091248, MAE: 0.7222684621810913, RMSE: 0.910979950113681\n",
      "Experiment 6 metrics at epoch 300: MSE: 1.0377110242843628, MAE: 0.8136131167411804, RMSE: 1.018681021853437\n",
      "Experiment 3 metrics at epoch 280: MSE: 1.0382260084152222, MAE: 0.8138803243637085, RMSE: 1.018933760563081\n",
      "Experiment 9 metrics at epoch 300: MSE: 1.1995395421981812, MAE: 0.8572567105293274, RMSE: 1.0952349255745002\n",
      "Experiment 5 metrics at epoch 300: MSE: 1.0202438831329346, MAE: 0.8056095838546753, RMSE: 1.0100712267622192\n"
     ]
    }
   ],
   "source": [
    "# Function to extract the epoch with the minimal validation loss for each experiment\n",
    "def minimal_val_loss_epoch(losses):\n",
    "    min_val_loss_epochs = {}\n",
    "    for experiment_nr in losses.keys():\n",
    "        val_loss = losses[experiment_nr]['val_loss']\n",
    "        min_epoch = np.argmin(val_loss) + 1  # +1 to convert from 0-indexed to 1-indexed epoch\n",
    "        # round the epoch to nearest number % 10 == 0\n",
    "        min_epoch = round(min_epoch / 10) * 10\n",
    "        min_val_loss_epochs[experiment_nr] = min_epoch\n",
    "    return min_val_loss_epochs\n",
    "\n",
    "min_val_loss_epochs = minimal_val_loss_epoch(losses)\n",
    "\n",
    "# Function to extract the metric values at the epoch with the minimal validation loss\n",
    "def metrics_at_min_val_loss(metrics, min_val_loss_epochs):\n",
    "    metrics_at_min_val = {}\n",
    "    for experiment_nr, epoch in min_val_loss_epochs.items():\n",
    "        if epoch in metrics[experiment_nr]:\n",
    "            metrics_at_min_val[experiment_nr] = metrics[experiment_nr][epoch]\n",
    "        else:\n",
    "            print(f\"Epoch {epoch} not found for Experiment {experiment_nr}\")\n",
    "    return metrics_at_min_val\n",
    "\n",
    "metrics_min_val_loss = metrics_at_min_val_loss(metrics, min_val_loss_epochs)\n",
    "\n",
    "print(\"Metrics at Minimal Validation Loss:\")\n",
    "for experiment_nr, metric in metrics_min_val_loss.items():\n",
    "    print(f\"Experiment {experiment_nr} metrics at epoch {min_val_loss_epochs[experiment_nr]}: MSE: {metric['mse']}, MAE: {metric['mae']}, RMSE: {metric['rmse']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d70149",
   "metadata": {},
   "source": [
    "## No Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b95511bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_no_metadata = torch.load('../losses/np/no-metadata/losses_np_no_metadata_epoch300.pt')\n",
    "metric_files_no_metadata = glob.glob('../metrics/np/no-metadata/metrics_np_*_epoch*.pt')\n",
    "\n",
    "# Load the metrics from each file and store them in a dictionary, with the experiment number as key \n",
    "metrics_no_metadata = {}\n",
    "for file in metric_files_no_metadata:\n",
    "    epoch = int(file.split('_')[-1].replace('epoch', '').replace('.pt', ''))  # Extract the epoch number\n",
    "    metrics_no_metadata[epoch] = torch.load(file, weights_only=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dca19d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_no_metadata(metrics):\n",
    "    # Plot the metrics for the no metadata experiment\n",
    "    epochs = sorted(metrics.keys())\n",
    "    mse = [metrics[epoch]['mse'] for epoch in epochs]\n",
    "    mae = [metrics[epoch]['mae'] for epoch in epochs]\n",
    "    plt.figure(figsize=fig_size)\n",
    "    plt.plot(epochs, mse, label='MSE', color='blue')\n",
    "    plt.plot(epochs, mae, label='MAE', color='orange')\n",
    "    plt.title('Metrics for No Metadata Experiment')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Metric Value')\n",
    "    plt.legend()\n",
    "    ax = plt.gca()\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    plt.savefig(f'{figure_base_path}metrics_no_metadata.pdf')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "plot_metrics_no_metadata(metrics_no_metadata)\n",
    "\n",
    "\n",
    "def plot_loss_no_metadata(losses):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    plt.plot(losses['train_loss'], label='Train Loss', color='blue')\n",
    "    plt.plot(losses['val_loss'], label='Validation Loss', color='orange', linestyle='--')\n",
    "    plt.title('Losses for No Metadata Experiment')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    ax = plt.gca()\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    plt.savefig(f'{figure_base_path}losses_no_metadata.pdf')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "plot_loss_no_metadata(losses_no_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36eab7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Experiment      RMSE       MSE       MAE\n",
      "0            1  0.910980  0.829884  0.722268\n",
      "1  No Metadata  1.004345  1.008709  0.796534\n"
     ]
    }
   ],
   "source": [
    "# Compare the metrics of the no metadata experiment with the results from the best experiment including metadata\n",
    "def compare_metrics(metrics, metrics_no_metadata, best_experiment):\n",
    "    # Get the metrics for the best experiment\n",
    "    best_metrics = metrics[best_experiment][300]\n",
    "    mse_best = best_metrics['mse']\n",
    "    mae_best = best_metrics['mae']\n",
    "    rmse_best = best_metrics['rmse']\n",
    "    \n",
    "    # Get the metrics for the no metadata experiment at epoch 100\n",
    "    mse_no_metadata = metrics_no_metadata[300]['mse']\n",
    "    mae_no_metadata = metrics_no_metadata[300]['mae']\n",
    "    \n",
    "    # Create a DataFrame for comparison\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Experiment': ['1', 'No Metadata'],\n",
    "        'RMSE': [rmse_best, metrics_no_metadata[300]['rmse']],\n",
    "        'MSE': [mse_best, mse_no_metadata],\n",
    "        'MAE': [mae_best, mae_no_metadata]\n",
    "    })\n",
    "    \n",
    "    print(comparison_df)\n",
    "\n",
    "compare_metrics(metrics, metrics_no_metadata, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "659e861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation losses of the no metadata experiment and the best experiment including metadata\n",
    "def plot_comparison_loss(losses, losses_no_metadata, best_experiment):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    \n",
    "    # Plot the best experiment\n",
    "    plt.plot(losses[best_experiment]['train_loss'], label='Train Loss (Best Experiment)', color='blue')\n",
    "    plt.plot(losses[best_experiment]['val_loss'], label='Validation Loss (Best Experiment)', color='orange')\n",
    "    \n",
    "    # Plot the no metadata experiment\n",
    "    plt.plot(losses_no_metadata['train_loss'], label='Train Loss (No Metadata)', color='blue', linestyle='--')\n",
    "    plt.plot(losses_no_metadata['val_loss'], label='Validation Loss (No Metadata)', color='orange', linestyle='--')\n",
    "    \n",
    "    plt.title('Comparison of Losses: Best Experiment vs No Metadata')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    ax = plt.gca()\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    plt.savefig(f'{figure_base_path}comparison_losses.pdf')\n",
    "    plt.close()\n",
    "\n",
    "plot_comparison_loss(losses, losses_no_metadata, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa7caf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation losses of the no metadata experiment and the best experiment including metadata\n",
    "def plot_comparison_loss(losses, losses_no_metadata, best_experiment):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    \n",
    "    # Only plot the last 100 epochs\n",
    "    train_loss_best = losses[best_experiment]['train_loss'][-100:]\n",
    "    val_loss_best = losses[best_experiment]['val_loss'][-100:]\n",
    "    train_loss_no_metadata = losses_no_metadata['train_loss'][-100:]\n",
    "    val_loss_no_metadata = losses_no_metadata['val_loss'][-100:]\n",
    "    epochs = range(len(losses[best_experiment]['train_loss']) - 99, len(losses[best_experiment]['train_loss']) + 1)\n",
    "    \n",
    "    plt.plot(epochs, train_loss_best, label='Train Loss (Best Experiment)', color='blue')\n",
    "    plt.plot(epochs, val_loss_best, label='Validation Loss (Best Experiment)', color='orange')\n",
    "    plt.plot(epochs, train_loss_no_metadata, label='Train Loss (No Metadata)', color='blue', linestyle='--')\n",
    "    plt.plot(epochs, val_loss_no_metadata, label='Validation Loss (No Metadata)', color='orange', linestyle='--')\n",
    "    \n",
    "    plt.title('Comparison of Losses (Last 100 Epochs): Best Experiment vs No Metadata')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    ax = plt.gca()\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    plt.savefig(f'{figure_base_path}comparison_losses_last100.pdf')\n",
    "    plt.close()\n",
    "\n",
    "plot_comparison_loss(losses, losses_no_metadata, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movielens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
